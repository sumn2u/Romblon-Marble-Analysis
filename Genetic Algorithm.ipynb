{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4gr-Rl4OjaeW",
        "outputId": "a050b0fc-a00c-4ac1-b72c-7253b2d2063d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M5_SeJMKkwql",
        "outputId": "607f3ca1-2f90-48f8-c443-ae1df8e31ee0"
      },
      "outputs": [],
      "source": [
        "!ls \"/content/drive/My Drive\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HPc68OoGkz3V"
      },
      "outputs": [],
      "source": [
        "!cp -r \"/content/drive/My Drive/marble\" \"marble\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cR0gKH5GldtF",
        "outputId": "b9d21d79-7033-457d-fbfa-40ef9b3b4683"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "'marble datasets'  'MINST Genetic Algorithm.ipynb'\n"
          ]
        }
      ],
      "source": [
        "!ls \"/content/marble\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CHkVJ0he5UTZ",
        "outputId": "f61e141e-b5f8-441b-cd6e-e06abaf783bd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total number of images in CLASS A 164\n",
            "Total number of images in CLASS B 245\n",
            "Total number of images in CLASS C 494\n"
          ]
        }
      ],
      "source": [
        "#count the number of images in respective directory\n",
        "import fnmatch\n",
        "import os\n",
        "print( \"Total number of images in CLASS A\", len(fnmatch.filter(os.listdir(\"/content/marble/marble datasets/CLASS A\"), '*.jpg')));\n",
        "print( \"Total number of images in CLASS B\", len(fnmatch.filter(os.listdir(\"/content/marble/marble datasets/CLASS B\"), '*.jpg')));\n",
        "print( \"Total number of images in CLASS C\", len(fnmatch.filter(os.listdir(\"/content/marble/marble datasets/CLASS C\"), '*.jpg')));"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3iS1_-Pz9F8Y"
      },
      "outputs": [],
      "source": [
        "# create final dataset.the training  dataset consits of (0.8 * 0.8 * T), the valdation dataset (0.2 * 0.8 * T) and (0.2 * T) testing images.\n",
        "# x_train: Numpy arrays of the images of the training dataset\n",
        "# y_train: Labels of the training dataset\n",
        "# x_test: Numpy arrays of the images of the testing dataset\n",
        "# y_test: Labels of the testing dataset\n",
        "# x_val: Numpy arrays of the images of the validation dataset\n",
        "# y_val: Labels of the validation dataset\n",
        "\n",
        "from tensorflow.keras.layers import Input, Lambda, Dense, Flatten,Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.applications.vgg19 import VGG19\n",
        "from tensorflow.keras.applications.vgg19 import preprocess_input\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Sequential\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8VlfnLNuS5no"
      },
      "outputs": [],
      "source": [
        "# re-size all the images to this\n",
        "IMAGE_SIZE = [224, 224]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oTiOf2igAk1P",
        "outputId": "02824b89-35f2-49a7-bf85-20efc302af61"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting python_splitter\n",
            "  Downloading python_splitter-0.0.3-py3-none-any.whl (5.2 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from python_splitter) (1.21.6)\n",
            "Installing collected packages: python-splitter\n",
            "Successfully installed python-splitter-0.0.3\n",
            "✅Checking SOURCE directory...\n",
            "0.64 0.2 0.16\n",
            "✅Checking percentage validation...\n",
            "✅Making required directories...\n",
            "✅Shuffling data...\n",
            "✅Getting ready for copying files...\n",
            "\n",
            "-------------Successfully splitted !!!--------------- \n"
          ]
        }
      ],
      "source": [
        "# split dataset into train_test_folder\n",
        "! pip install python_splitter \n",
        "import python_splitter\n",
        "python_splitter.split_from_folder(\"/content/marble/marble datasets\", train=0.64, test=0.16, val=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WXWCnVa79692"
      },
      "outputs": [],
      "source": [
        "train_path=\"Train_Test_Folder/train\"\n",
        "test_path=\"Train_Test_Folder/test\"\n",
        "val_path=\"Train_Test_Folder/val\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jvvIazXO-OTS"
      },
      "outputs": [],
      "source": [
        "x_train=[]\n",
        "\n",
        "for folder in os.listdir(train_path):\n",
        "    sub_path=train_path+\"/\"+folder\n",
        "    for img in os.listdir(sub_path):\n",
        "        image_path=sub_path+\"/\"+img\n",
        "        img_arr=cv2.imread(image_path)\n",
        "        img_arr=cv2.resize(img_arr,(224,224))\n",
        "        x_train.append(img_arr)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BVDN4WG7TxO0"
      },
      "outputs": [],
      "source": [
        "x_test=[]\n",
        "\n",
        "for folder in os.listdir(test_path):\n",
        "    sub_path=test_path+\"/\"+folder\n",
        "    for img in os.listdir(sub_path):\n",
        "        image_path=sub_path+\"/\"+img\n",
        "        img_arr=cv2.imread(image_path)\n",
        "        img_arr=cv2.resize(img_arr,(224,224))\n",
        "        x_test.append(img_arr)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eH37Jr-UT6aD"
      },
      "outputs": [],
      "source": [
        "x_val=[]\n",
        "\n",
        "for folder in os.listdir(val_path):\n",
        "    sub_path=val_path+\"/\"+folder\n",
        "    for img in os.listdir(sub_path):\n",
        "        image_path=sub_path+\"/\"+img\n",
        "        img_arr=cv2.imread(image_path)\n",
        "        img_arr=cv2.resize(img_arr,(224,224))\n",
        "        x_val.append(img_arr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5mil7-YcCdYj"
      },
      "outputs": [],
      "source": [
        "# _train,x_test, and x_val divided by 255.0 for normalization.\n",
        "train_x=np.array(x_train)\n",
        "test_x=np.array(x_test)\n",
        "val_x=np.array(x_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bLMF0SwRUS7P",
        "outputId": "cbc8df9e-f0d5-4f6e-e497-375434724650"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((576, 224, 224, 3), (181, 224, 224, 3), (146, 224, 224, 3))"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_x.shape,test_x.shape,val_x.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dkPCSAGbUSPl"
      },
      "outputs": [],
      "source": [
        "train_x=train_x/255.0\n",
        "test_x=test_x/255.0\n",
        "val_x=val_x/255.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xfp24DhxC1bn"
      },
      "outputs": [],
      "source": [
        "#labels of the corresponding datasets using ImageDataGenerator.\n",
        "train_datagen = ImageDataGenerator(rescale = 1./255)\n",
        "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
        "val_datagen = ImageDataGenerator(rescale = 1./255)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hj9rz-fnC7wx",
        "outputId": "e1d0a466-5740-4096-ee39-1c3448f9ceff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 576 images belonging to 3 classes.\n",
            "Found 181 images belonging to 3 classes.\n",
            "Found 146 images belonging to 3 classes.\n"
          ]
        }
      ],
      "source": [
        "training_set = train_datagen.flow_from_directory(train_path,\n",
        "                                                 target_size = (224, 224),\n",
        "                                                 batch_size = 32,\n",
        "                                                 class_mode = 'sparse')\n",
        "test_set = test_datagen.flow_from_directory(test_path,\n",
        "                                            target_size = (224, 224),\n",
        "                                            batch_size = 32,\n",
        "                                            class_mode = 'sparse')\n",
        "val_set = val_datagen.flow_from_directory(val_path,\n",
        "                                            target_size = (224, 224),\n",
        "                                            batch_size = 32,\n",
        "                                            class_mode = 'sparse')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kzJmFg5JDJ8j",
        "outputId": "dfa9665b-9cbc-41e7-f5cf-6f4140a69ae9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'CLASS A': 0, 'CLASS B': 1, 'CLASS C': 2}"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "training_set.class_indices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B6A4eFybDV-D",
        "outputId": "9078b454-1da3-4d5c-f0a5-bdaa22d733ac"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((576,), (181,), (146,))"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_y=training_set.classes\n",
        "test_y=test_set.classes\n",
        "val_y=val_set.classes\n",
        "train_y.shape,test_y.shape,val_y.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aaBXuUQAzBTI"
      },
      "outputs": [],
      "source": [
        "from tensorflow.core.protobuf.config_pb2 import ConfigProto\n",
        "# from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.layers import Dense, Conv2D, Dropout, Flatten, MaxPooling2D\n",
        "from tensorflow.python.client.session import InteractiveSession\n",
        "from tensorflow.python.keras.utils.np_utils import to_categorical\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "config = ConfigProto()\n",
        "config.gpu_options.allow_growth = True\n",
        "session = InteractiveSession(config=config)\n",
        "\n",
        "# add preprocessing layer to the front of VGG\n",
        "vgg = VGG19(input_shape=IMAGE_SIZE + [3], weights='imagenet', include_top=False)\n",
        "# don't train existing weights\n",
        "for layer in vgg.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uWj95oXhzSBu"
      },
      "outputs": [],
      "source": [
        "\n",
        "def init():\n",
        "    # our layers - you can add more if you want\n",
        "    x = Flatten()(vgg.output)\n",
        "    prediction = Dense(3, activation='softmax')(x)\n",
        "    # create a model object \n",
        "    model = Model(inputs=vgg.input, outputs=prediction)\n",
        "    # tell the model what cost and optimization method to use\n",
        "    model.compile(\n",
        "      loss='sparse_categorical_crossentropy',\n",
        "      optimizer=\"adam\",\n",
        "      metrics=['accuracy']\n",
        "    )\n",
        "    print(model.summary())\n",
        "    return model\n",
        "\n",
        "\n",
        "def train(models):\n",
        "    losses = []\n",
        "    early_stop=EarlyStopping(monitor='val_loss',mode='min',verbose=1,patience=5)\n",
        "    for i in range(len(models)):\n",
        "        history =  models[i].fit(\n",
        "                    train_x,\n",
        "                    train_y,\n",
        "                    validation_data=(val_x,val_y),\n",
        "                    epochs=10,\n",
        "                    callbacks=[early_stop],\n",
        "                    batch_size=32,shuffle=True)\n",
        "        losses.append(round(history.history['loss'][-1], 4))\n",
        "    return models, losses\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OCNQI1xezxI_",
        "outputId": "4ae027a2-f256-4a78-9fba-21797de5c1cc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "18/18 [==============================] - 16s 343ms/step - loss: 1.0011 - accuracy: 0.5972 - val_loss: 0.9730 - val_accuracy: 0.6438\n",
            "Epoch 2/10\n",
            "18/18 [==============================] - 4s 219ms/step - loss: 0.7382 - accuracy: 0.6892 - val_loss: 0.9900 - val_accuracy: 0.6164\n",
            "Epoch 3/10\n",
            "18/18 [==============================] - 4s 220ms/step - loss: 0.6140 - accuracy: 0.7448 - val_loss: 0.8209 - val_accuracy: 0.6370\n",
            "Epoch 4/10\n",
            "18/18 [==============================] - 4s 221ms/step - loss: 0.5299 - accuracy: 0.7847 - val_loss: 0.8876 - val_accuracy: 0.6164\n",
            "Epoch 5/10\n",
            "18/18 [==============================] - 4s 221ms/step - loss: 0.4610 - accuracy: 0.8142 - val_loss: 0.9364 - val_accuracy: 0.6096\n",
            "Epoch 6/10\n",
            "18/18 [==============================] - 4s 222ms/step - loss: 0.4011 - accuracy: 0.8594 - val_loss: 1.0127 - val_accuracy: 0.6370\n",
            "Epoch 7/10\n",
            "18/18 [==============================] - 4s 222ms/step - loss: 0.4520 - accuracy: 0.8212 - val_loss: 0.9722 - val_accuracy: 0.6370\n",
            "Epoch 8/10\n",
            "18/18 [==============================] - 4s 223ms/step - loss: 0.4335 - accuracy: 0.8264 - val_loss: 0.9155 - val_accuracy: 0.6164\n",
            "Epoch 8: early stopping\n",
            "Epoch 1/10\n",
            "18/18 [==============================] - 5s 242ms/step - loss: 1.4069 - accuracy: 0.4653 - val_loss: 0.9483 - val_accuracy: 0.5890\n",
            "Epoch 2/10\n",
            "18/18 [==============================] - 4s 250ms/step - loss: 0.8361 - accuracy: 0.6580 - val_loss: 1.0803 - val_accuracy: 0.5890\n",
            "Epoch 3/10\n",
            "18/18 [==============================] - 4s 224ms/step - loss: 0.7206 - accuracy: 0.6979 - val_loss: 0.8585 - val_accuracy: 0.6027\n",
            "Epoch 4/10\n",
            "18/18 [==============================] - 4s 226ms/step - loss: 0.6582 - accuracy: 0.7188 - val_loss: 0.8397 - val_accuracy: 0.6027\n",
            "Epoch 5/10\n",
            "18/18 [==============================] - 4s 225ms/step - loss: 0.5121 - accuracy: 0.7882 - val_loss: 0.8429 - val_accuracy: 0.6507\n",
            "Epoch 6/10\n",
            "18/18 [==============================] - 4s 226ms/step - loss: 0.4850 - accuracy: 0.8281 - val_loss: 0.7997 - val_accuracy: 0.6233\n",
            "Epoch 7/10\n",
            "18/18 [==============================] - 4s 226ms/step - loss: 0.4267 - accuracy: 0.8472 - val_loss: 0.8480 - val_accuracy: 0.6438\n",
            "Epoch 8/10\n",
            "18/18 [==============================] - 4s 227ms/step - loss: 0.3909 - accuracy: 0.8715 - val_loss: 0.8361 - val_accuracy: 0.6370\n",
            "Epoch 9/10\n",
            "18/18 [==============================] - 4s 228ms/step - loss: 0.3491 - accuracy: 0.9010 - val_loss: 0.8737 - val_accuracy: 0.6027\n",
            "Epoch 10/10\n",
            "18/18 [==============================] - 4s 229ms/step - loss: 0.3322 - accuracy: 0.9010 - val_loss: 0.8479 - val_accuracy: 0.6233\n",
            "Epoch 1/10\n",
            "18/18 [==============================] - 5s 255ms/step - loss: 1.4592 - accuracy: 0.5000 - val_loss: 1.1936 - val_accuracy: 0.5616\n",
            "Epoch 2/10\n",
            "18/18 [==============================] - 4s 230ms/step - loss: 0.9341 - accuracy: 0.6319 - val_loss: 0.9869 - val_accuracy: 0.6096\n",
            "Epoch 3/10\n",
            "18/18 [==============================] - 4s 232ms/step - loss: 0.7063 - accuracy: 0.7083 - val_loss: 0.8508 - val_accuracy: 0.6027\n",
            "Epoch 4/10\n",
            "18/18 [==============================] - 4s 233ms/step - loss: 0.5815 - accuracy: 0.7743 - val_loss: 0.8460 - val_accuracy: 0.6096\n",
            "Epoch 5/10\n",
            "18/18 [==============================] - 4s 232ms/step - loss: 0.5177 - accuracy: 0.8229 - val_loss: 0.8399 - val_accuracy: 0.6438\n",
            "Epoch 6/10\n",
            "18/18 [==============================] - 4s 234ms/step - loss: 0.4711 - accuracy: 0.8229 - val_loss: 0.9019 - val_accuracy: 0.6027\n",
            "Epoch 7/10\n",
            "18/18 [==============================] - 4s 235ms/step - loss: 0.4216 - accuracy: 0.8559 - val_loss: 0.8750 - val_accuracy: 0.6301\n",
            "Epoch 8/10\n",
            "18/18 [==============================] - 4s 233ms/step - loss: 0.3783 - accuracy: 0.8854 - val_loss: 0.9046 - val_accuracy: 0.6027\n",
            "Epoch 9/10\n",
            "18/18 [==============================] - 4s 234ms/step - loss: 0.3655 - accuracy: 0.8872 - val_loss: 0.8750 - val_accuracy: 0.6301\n",
            "Epoch 10/10\n",
            "18/18 [==============================] - 4s 234ms/step - loss: 0.3473 - accuracy: 0.8906 - val_loss: 0.9303 - val_accuracy: 0.6027\n",
            "Epoch 10: early stopping\n",
            "[0.4335, 0.3322, 0.3473]\n",
            "Epoch 1/10\n",
            "18/18 [==============================] - 4s 240ms/step - loss: 0.3027 - accuracy: 0.9097 - val_loss: 0.8837 - val_accuracy: 0.6301\n",
            "Epoch 2/10\n",
            "18/18 [==============================] - 5s 258ms/step - loss: 0.2808 - accuracy: 0.9236 - val_loss: 0.9370 - val_accuracy: 0.6233\n",
            "Epoch 3/10\n",
            "18/18 [==============================] - 4s 234ms/step - loss: 0.2617 - accuracy: 0.9462 - val_loss: 0.9123 - val_accuracy: 0.6301\n",
            "Epoch 4/10\n",
            "18/18 [==============================] - 4s 235ms/step - loss: 0.2565 - accuracy: 0.9236 - val_loss: 0.8871 - val_accuracy: 0.6233\n",
            "Epoch 5/10\n",
            "18/18 [==============================] - 4s 237ms/step - loss: 0.2388 - accuracy: 0.9427 - val_loss: 0.9286 - val_accuracy: 0.6233\n",
            "Epoch 6/10\n",
            "18/18 [==============================] - 4s 238ms/step - loss: 0.2323 - accuracy: 0.9583 - val_loss: 1.0861 - val_accuracy: 0.6301\n",
            "Epoch 6: early stopping\n",
            "Epoch 1/10\n",
            "18/18 [==============================] - 4s 248ms/step - loss: 0.3059 - accuracy: 0.9010 - val_loss: 0.9213 - val_accuracy: 0.6370\n",
            "Epoch 2/10\n",
            "18/18 [==============================] - 4s 244ms/step - loss: 0.2930 - accuracy: 0.9219 - val_loss: 0.8992 - val_accuracy: 0.6370\n",
            "Epoch 3/10\n",
            "18/18 [==============================] - 4s 246ms/step - loss: 0.2686 - accuracy: 0.9340 - val_loss: 0.8940 - val_accuracy: 0.6096\n",
            "Epoch 4/10\n",
            "18/18 [==============================] - 4s 249ms/step - loss: 0.2378 - accuracy: 0.9462 - val_loss: 0.9053 - val_accuracy: 0.6096\n",
            "Epoch 5/10\n",
            "18/18 [==============================] - 4s 251ms/step - loss: 0.2267 - accuracy: 0.9497 - val_loss: 0.9850 - val_accuracy: 0.5890\n",
            "Epoch 6/10\n",
            "18/18 [==============================] - 4s 252ms/step - loss: 0.2326 - accuracy: 0.9375 - val_loss: 1.0211 - val_accuracy: 0.5959\n",
            "Epoch 7/10\n",
            "18/18 [==============================] - 5s 254ms/step - loss: 0.2242 - accuracy: 0.9392 - val_loss: 0.9902 - val_accuracy: 0.6370\n",
            "Epoch 8/10\n",
            "18/18 [==============================] - 4s 252ms/step - loss: 0.2010 - accuracy: 0.9566 - val_loss: 0.9737 - val_accuracy: 0.6164\n",
            "Epoch 8: early stopping\n",
            "Epoch 1/10\n",
            "18/18 [==============================] - 5s 252ms/step - loss: 0.2153 - accuracy: 0.9427 - val_loss: 0.9333 - val_accuracy: 0.6301\n",
            "Epoch 2/10\n",
            "18/18 [==============================] - 4s 248ms/step - loss: 0.1988 - accuracy: 0.9601 - val_loss: 0.9858 - val_accuracy: 0.6233\n",
            "Epoch 3/10\n",
            "18/18 [==============================] - 4s 248ms/step - loss: 0.1936 - accuracy: 0.9497 - val_loss: 0.9999 - val_accuracy: 0.5890\n",
            "Epoch 4/10\n",
            "18/18 [==============================] - 4s 248ms/step - loss: 0.1870 - accuracy: 0.9531 - val_loss: 0.9716 - val_accuracy: 0.6233\n",
            "Epoch 5/10\n",
            "18/18 [==============================] - 4s 247ms/step - loss: 0.1773 - accuracy: 0.9618 - val_loss: 0.9693 - val_accuracy: 0.6233\n",
            "Epoch 6/10\n",
            "18/18 [==============================] - 4s 247ms/step - loss: 0.1615 - accuracy: 0.9792 - val_loss: 1.1298 - val_accuracy: 0.6233\n",
            "Epoch 6: early stopping\n",
            "Epoch 1/10\n",
            "18/18 [==============================] - 4s 244ms/step - loss: 0.1711 - accuracy: 0.9583 - val_loss: 0.9957 - val_accuracy: 0.6438\n",
            "Epoch 2/10\n",
            "18/18 [==============================] - 4s 239ms/step - loss: 0.1491 - accuracy: 0.9774 - val_loss: 0.9890 - val_accuracy: 0.6370\n",
            "Epoch 3/10\n",
            "18/18 [==============================] - 4s 242ms/step - loss: 0.1364 - accuracy: 0.9809 - val_loss: 1.0255 - val_accuracy: 0.6027\n",
            "Epoch 4/10\n",
            "18/18 [==============================] - 4s 244ms/step - loss: 0.1336 - accuracy: 0.9826 - val_loss: 1.0550 - val_accuracy: 0.6301\n",
            "Epoch 5/10\n",
            "18/18 [==============================] - 4s 242ms/step - loss: 0.1224 - accuracy: 0.9809 - val_loss: 1.1165 - val_accuracy: 0.6164\n",
            "Epoch 6/10\n",
            "18/18 [==============================] - 5s 265ms/step - loss: 0.1365 - accuracy: 0.9722 - val_loss: 1.0294 - val_accuracy: 0.6233\n",
            "Epoch 7/10\n",
            "18/18 [==============================] - 4s 245ms/step - loss: 0.1118 - accuracy: 0.9826 - val_loss: 1.1082 - val_accuracy: 0.6233\n",
            "Epoch 7: early stopping\n",
            "[0.2323, 0.201, 0.1615, 0.1118]\n",
            "Epoch 1/10\n",
            "18/18 [==============================] - 4s 243ms/step - loss: 0.1097 - accuracy: 0.9861 - val_loss: 1.1203 - val_accuracy: 0.5890\n",
            "Epoch 2/10\n",
            "18/18 [==============================] - 4s 238ms/step - loss: 0.1112 - accuracy: 0.9774 - val_loss: 1.1251 - val_accuracy: 0.6233\n",
            "Epoch 3/10\n",
            "18/18 [==============================] - 4s 239ms/step - loss: 0.0969 - accuracy: 0.9878 - val_loss: 1.1215 - val_accuracy: 0.5959\n",
            "Epoch 4/10\n",
            "18/18 [==============================] - 4s 239ms/step - loss: 0.1070 - accuracy: 0.9826 - val_loss: 1.1734 - val_accuracy: 0.6233\n",
            "Epoch 5/10\n",
            "18/18 [==============================] - 4s 240ms/step - loss: 0.0952 - accuracy: 0.9844 - val_loss: 1.1254 - val_accuracy: 0.6096\n",
            "Epoch 6/10\n",
            "18/18 [==============================] - 4s 241ms/step - loss: 0.0913 - accuracy: 0.9861 - val_loss: 1.1061 - val_accuracy: 0.6233\n",
            "Epoch 7/10\n",
            "18/18 [==============================] - 4s 241ms/step - loss: 0.1007 - accuracy: 0.9826 - val_loss: 1.2113 - val_accuracy: 0.6301\n",
            "Epoch 8/10\n",
            "18/18 [==============================] - 4s 242ms/step - loss: 0.0872 - accuracy: 0.9878 - val_loss: 1.1291 - val_accuracy: 0.6164\n",
            "Epoch 9/10\n",
            "18/18 [==============================] - 4s 242ms/step - loss: 0.0799 - accuracy: 0.9878 - val_loss: 1.1540 - val_accuracy: 0.6164\n",
            "Epoch 10/10\n",
            "18/18 [==============================] - 4s 243ms/step - loss: 0.0811 - accuracy: 0.9896 - val_loss: 1.1787 - val_accuracy: 0.6164\n",
            "Epoch 1/10\n",
            "18/18 [==============================] - 4s 252ms/step - loss: 0.0781 - accuracy: 0.9878 - val_loss: 1.1364 - val_accuracy: 0.6301\n",
            "Epoch 2/10\n",
            "18/18 [==============================] - 4s 245ms/step - loss: 0.0848 - accuracy: 0.9792 - val_loss: 1.1739 - val_accuracy: 0.6096\n",
            "Epoch 3/10\n",
            "18/18 [==============================] - 4s 245ms/step - loss: 0.0796 - accuracy: 0.9792 - val_loss: 1.1999 - val_accuracy: 0.6096\n",
            "Epoch 4/10\n",
            "18/18 [==============================] - 4s 246ms/step - loss: 0.0787 - accuracy: 0.9878 - val_loss: 1.3363 - val_accuracy: 0.6301\n",
            "Epoch 5/10\n",
            "18/18 [==============================] - 4s 246ms/step - loss: 0.0838 - accuracy: 0.9896 - val_loss: 1.1418 - val_accuracy: 0.6233\n",
            "Epoch 6/10\n",
            "18/18 [==============================] - 4s 247ms/step - loss: 0.0792 - accuracy: 0.9878 - val_loss: 1.3849 - val_accuracy: 0.6164\n",
            "Epoch 6: early stopping\n",
            "Epoch 1/10\n",
            "18/18 [==============================] - 4s 252ms/step - loss: 0.0793 - accuracy: 0.9844 - val_loss: 1.1737 - val_accuracy: 0.6164\n",
            "Epoch 2/10\n",
            "18/18 [==============================] - 4s 246ms/step - loss: 0.0696 - accuracy: 0.9826 - val_loss: 1.1820 - val_accuracy: 0.6233\n",
            "Epoch 3/10\n",
            "18/18 [==============================] - 4s 247ms/step - loss: 0.0641 - accuracy: 0.9878 - val_loss: 1.3229 - val_accuracy: 0.6301\n",
            "Epoch 4/10\n",
            "18/18 [==============================] - 4s 247ms/step - loss: 0.0639 - accuracy: 0.9861 - val_loss: 1.2389 - val_accuracy: 0.6233\n",
            "Epoch 5/10\n",
            "18/18 [==============================] - 4s 248ms/step - loss: 0.0643 - accuracy: 0.9878 - val_loss: 1.2076 - val_accuracy: 0.6233\n",
            "Epoch 6/10\n",
            "18/18 [==============================] - 4s 247ms/step - loss: 0.0643 - accuracy: 0.9844 - val_loss: 1.2787 - val_accuracy: 0.6096\n",
            "Epoch 6: early stopping\n",
            "Epoch 1/10\n",
            "18/18 [==============================] - 4s 242ms/step - loss: 0.0613 - accuracy: 0.9844 - val_loss: 1.3514 - val_accuracy: 0.6164\n",
            "Epoch 2/10\n",
            "18/18 [==============================] - 4s 238ms/step - loss: 0.0599 - accuracy: 0.9844 - val_loss: 1.2221 - val_accuracy: 0.6164\n",
            "Epoch 3/10\n",
            "18/18 [==============================] - 4s 243ms/step - loss: 0.0557 - accuracy: 0.9826 - val_loss: 1.2733 - val_accuracy: 0.6027\n",
            "Epoch 4/10\n",
            "18/18 [==============================] - 4s 244ms/step - loss: 0.0508 - accuracy: 0.9878 - val_loss: 1.3463 - val_accuracy: 0.6233\n",
            "Epoch 5/10\n",
            "18/18 [==============================] - 4s 240ms/step - loss: 0.0555 - accuracy: 0.9861 - val_loss: 1.2762 - val_accuracy: 0.6096\n",
            "Epoch 6/10\n",
            "18/18 [==============================] - 5s 264ms/step - loss: 0.0579 - accuracy: 0.9844 - val_loss: 1.2744 - val_accuracy: 0.6096\n",
            "Epoch 7/10\n",
            "18/18 [==============================] - 4s 243ms/step - loss: 0.0526 - accuracy: 0.9878 - val_loss: 1.3743 - val_accuracy: 0.6164\n",
            "Epoch 7: early stopping\n",
            "[0.0811, 0.0792, 0.0643, 0.0526]\n"
          ]
        }
      ],
      "source": [
        "import random\n",
        "\n",
        "no_of_generations = 10\n",
        "no_of_individuals = 3\n",
        "mutate_factor = 0.05\n",
        "individuals = []\n",
        "\n",
        "layers = []\n",
        "\n",
        "\n",
        "def mutate(new_individual):\n",
        "    for layer in layers:\n",
        "        for bias in range(len(new_individual.layers[layer].get_weights()[1])):\n",
        "            n = random.random()\n",
        "            if n < mutate_factor:\n",
        "                new_individual.layers[layer].get_weights(\n",
        "                )[1][bias] *= random.uniform(-0.5, 0.5)\n",
        "\n",
        "    for layer in layers:\n",
        "        for weight in new_individual.layers[layer].get_weights()[0]:\n",
        "            n = random.random()\n",
        "            if n < mutate_factor:\n",
        "                for j in range(len(weight)):\n",
        "                    if random.random() < mutate_factor:\n",
        "                        new_individual.layers[layer].get_weights(\n",
        "                        )[0][j] *= random.uniform(-0.5, 0.5)\n",
        "\n",
        "    return new_individual\n",
        "\n",
        "\n",
        "def crossover(individuals_param):\n",
        "    new_individuals = [individuals_param[0], individuals_param[1]]\n",
        "\n",
        "    for j in range(2, no_of_individuals):\n",
        "        if j < (no_of_individuals - 2):\n",
        "            if j == 2:\n",
        "                parentA = random.choice(individuals_param[:3])\n",
        "                parentB = random.choice(individuals_param[:3])\n",
        "            else:\n",
        "                parentA = random.choice(individuals_param[:])\n",
        "                parentB = random.choice(individuals_param[:])\n",
        "\n",
        "            for j in layers:\n",
        "                print(parentA.layers)\n",
        "                temp = parentA.layers[j].get_weights()[1]\n",
        "                parentA.layers[j].get_weights(\n",
        "                )[1] = parentB.layers[j].get_weights()[1]\n",
        "                parentB.layers[j].get_weights()[1] = temp\n",
        "\n",
        "            new_individual = random.choice([parentA, parentB])\n",
        "\n",
        "        else:\n",
        "            new_individual = random.choice(individuals_param[:])\n",
        "\n",
        "        new_individuals.append(mutate(new_individual))\n",
        "        new_individuals.append(new_individual)\n",
        "\n",
        "    return new_individuals\n",
        "\n",
        "\n",
        "def evolve(individuals_param, losses_param):\n",
        "    sorted_y_idx_list = sorted(range(len(losses_param)), key=lambda x: losses_param[x])\n",
        "    individuals_param = [individuals_param[x] for x in sorted_y_idx_list]\n",
        "\n",
        "    # winners = individuals[:6]\n",
        "\n",
        "    new_individuals = crossover(individuals_param)\n",
        "\n",
        "    return new_individuals\n",
        "\n",
        "\n",
        "\n",
        " #main ops\n",
        "for i in range(no_of_individuals):\n",
        "    individuals.append(init())\n",
        "\n",
        "for generation in range(no_of_generations):\n",
        "    individuals, losses = train(individuals)\n",
        "    print(losses)\n",
        "\n",
        "    individuals = evolve(individuals, losses)\n",
        "\n",
        "individuals[0].save(\"cnn1.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PuzC-SUe0oiG"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "import numpy as np\n",
        "model = load_model(\"cnn.h5\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BdsKcAQEiwOU",
        "outputId": "c247872f-d964-469c-a633-e08d4b775524"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "6/6 [==============================] - 1s 181ms/step\n"
          ]
        }
      ],
      "source": [
        "predicted_classes = model.predict(test_x)\n",
        "predicted_classes = np.argmax(predicted_classes, axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MwDc6xvxinYY",
        "outputId": "019c6c6c-45df-499c-f17e-2def89a00181"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "     Class 0       0.25      0.12      0.16        33\n",
            "     Class 1       0.45      0.51      0.48        49\n",
            "     Class 2       0.77      0.85      0.81        99\n",
            "\n",
            "    accuracy                           0.62       181\n",
            "   macro avg       0.49      0.49      0.48       181\n",
            "weighted avg       0.59      0.62      0.60       181\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "num_classes = 3\n",
        "target_names = [f\"Class {i}\" for i in range(num_classes)]\n",
        "\n",
        "print(classification_report(test_y, predicted_classes, target_names = target_names))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        },
        "id": "sPQTfFxTiHIN",
        "outputId": "aeb68f58-1b32-41eb-dcda-12eae874b22e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fc8916526d0>"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1008x720 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import matplotlib.pyplot as plt \n",
        "import seaborn as sns\n",
        "\n",
        "%matplotlib inline\n",
        "sns.set_style(\"whitegrid\")\n",
        "\n",
        "cm = confusion_matrix(test_y, predicted_classes)\n",
        "plt.figure(figsize = (14,10))\n",
        "sns.heatmap(cm, annot=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HSrQIF-0DAXa",
        "outputId": "652a1d2a-6a89-4962-e844-be85a60f380b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 1s 691ms/step\n",
            "Model output: [[0.9122951  0.03401291 0.05369195]]\n",
            "Value with highest probability: 0 %91.23\n"
          ]
        }
      ],
      "source": [
        "\n",
        "random_idx = np.random.randint(0, len(train_x))\n",
        "input_shape = (224, 224, 3)\n",
        "output = model.predict(train_x[random_idx].reshape(1, *input_shape))\n",
        "idx = np.argmax(output[0])\n",
        "print(\"Model output: {0}\".format(output))\n",
        "print(\"Value with highest probability: {0} %{1:.2f}\".format(idx, (output[0][idx]*100)))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.9.6 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.6"
    },
    "vscode": {
      "interpreter": {
        "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
